"""
Script de debug para scraping web con sesi√≥n persistente
Ejecutar con: python debug_scraper.py
"""
import asyncio
import os
from pathlib import Path
from playwright.async_api import async_playwright, Browser, BrowserContext, Page


class DebugScraper:
    def __init__(self, headless: bool = False, session_file: str = "state.json"):
        self.headless = headless
        self.browser: Browser | None = None
        self.context: BrowserContext | None = None
        self.page: Page | None = None
        self.playwright = None
        # Usar el archivo state.json del proyecto
        self.session_file = Path(session_file).resolve()
        
    async def iniciar_sesion(self, url: str = "https://www.google.com"):
        """Inicializa el navegador y carga la sesi√≥n desde state.json"""
        print("üöÄ Iniciando navegador...")
        
        self.playwright = await async_playwright().start()
        
        # Verificar si existe el archivo de sesi√≥n
        if self.session_file.exists():
            print(f"‚úÖ Archivo de sesi√≥n encontrado: {self.session_file}")
        else:
            print(f"‚ö†Ô∏è  Archivo de sesi√≥n NO encontrado: {self.session_file}")
            print("   El navegador se iniciar√° sin sesi√≥n guardada")
        
        # Iniciar navegador
        self.browser = await self.playwright.chromium.launch(
            headless=self.headless,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--no-sandbox',
            ],
        )
        
        # Crear contexto con sesi√≥n guardada (si existe)
        context_options = {
            'viewport': {'width': 1280, 'height': 720},
        }
        
        if self.session_file.exists():
            context_options['storage_state'] = str(self.session_file)
            print("üîë Cargando sesi√≥n desde state.json...")
        
        self.context = await self.browser.new_context(**context_options)
        
        # Crear nueva p√°gina
        self.page = await self.context.new_page()
        
        print(f"‚úÖ Navegador iniciado (headless={self.headless})")
        
        # Navegar a URL inicial
        print(f"üåê Navegando a: {url}")
        await self.page.goto(url, wait_until="networkidle")
        print("‚úÖ P√°gina cargada")
        
        return self.page
    
    async def listar_directorio(self):
        """Lista elementos en la p√°gina actual (similar a listar directorio)"""
        print("\nüìÇ LISTANDO ELEMENTOS EN LA P√ÅGINA:")
        print("=" * 60)
        
        # Listar links
        links = await self.page.locator('a').all()
        print(f"\nüîó Links encontrados: {len(links)}")
        for i, link in enumerate(links[:10], 1):  # Primeros 10
            try:
                text = await link.inner_text()
                href = await link.get_attribute('href')
                print(f"  {i}. {text[:50]} -> {href}")
            except:
                pass
        
        # Listar im√°genes
        images = await self.page.locator('img').all()
        print(f"\nüñºÔ∏è  Im√°genes encontradas: {len(images)}")
        for i, img in enumerate(images[:5], 1):  # Primeras 5
            try:
                src = await img.get_attribute('src')
                alt = await img.get_attribute('alt')
                print(f"  {i}. {alt} -> {src}")
            except:
                pass
        
        # Listar botones
        buttons = await self.page.locator('button').all()
        print(f"\nüîò Botones encontrados: {len(buttons)}")
        for i, btn in enumerate(buttons[:10], 1):
            try:
                text = await btn.inner_text()
                print(f"  {i}. {text[:50]}")
            except:
                pass
        
        print("=" * 60)
    
    async def extraer_datos(self, selector: str):
        """Extrae datos de un selector espec√≠fico"""
        print(f"\nüîç Extrayendo datos de: {selector}")
        elementos = await self.page.locator(selector).all()
        
        datos = []
        for elemento in elementos:
            try:
                texto = await elemento.inner_text()
                datos.append(texto)
            except:
                pass
        
        print(f"‚úÖ Extra√≠dos {len(datos)} elementos")
        return datos
    
    async def esperar_elemento(self, selector: str, timeout: int = 5000):
        """Espera a que un elemento est√© visible"""
        print(f"‚è≥ Esperando elemento: {selector}")
        try:
            await self.page.wait_for_selector(selector, timeout=timeout)
            print("‚úÖ Elemento encontrado")
            return True
        except Exception as e:
            print(f"‚ùå Error esperando elemento: {e}")
            return False
    
    async def click_elemento(self, selector: str):
        """Hace click en un elemento"""
        print(f"üñ±Ô∏è  Haciendo click en: {selector}")
        try:
            await self.page.click(selector)
            print("‚úÖ Click exitoso")
            return True
        except Exception as e:
            print(f"‚ùå Error al hacer click: {e}")
            return False
    
    async def llenar_formulario(self, campos: dict):
        """Llena un formulario con los datos proporcionados"""
        print("üìù Llenando formulario...")
        for selector, valor in campos.items():
            try:
                await self.page.fill(selector, valor)
                print(f"  ‚úÖ {selector} = {valor}")
            except Exception as e:
                print(f"  ‚ùå Error en {selector}: {e}")
    
    async def tomar_screenshot(self, nombre: str = "screenshot.png"):
        """Toma una captura de pantalla"""
        ruta = Path(__file__).parent / nombre
        await self.page.screenshot(path=str(ruta))
        print(f"üì∏ Screenshot guardado: {ruta}")
    
    async def obtener_cookies(self):
        """Obtiene las cookies de la sesi√≥n actual"""
        cookies = await self.context.cookies()
        print(f"\nüç™ Cookies encontradas: {len(cookies)}")
        for cookie in cookies:
            print(f"  - {cookie['name']}: {cookie['value'][:20]}...")
        return cookies
    
    async def ejecutar_javascript(self, script: str):
        """Ejecuta JavaScript en la p√°gina"""
        print(f"‚ö° Ejecutando JavaScript...")
        resultado = await self.page.evaluate(script)
        print(f"‚úÖ Resultado: {resultado}")
        return resultado
    
    async def guardar_sesion(self, archivo: str = "state.json"):
        """Guarda la sesi√≥n actual en un archivo"""
        ruta = Path(archivo).resolve()
        storage = await self.context.storage_state()
        import json
        with open(ruta, 'w') as f:
            json.dump(storage, f, indent=2)
        print(f"üíæ Sesi√≥n guardada en: {ruta}")
    
    async def cerrar(self):
        """Cierra el navegador"""
        try:
            if self.context:
                await self.context.close()
            if self.browser:
                await self.browser.close()
            if self.playwright:
                await self.playwright.stop()
            print("üîí Navegador cerrado")
        except Exception as e:
            print(f"‚ö†Ô∏è  Error al cerrar (ignorado): {e}")


from urllib.parse import unquote

async def esperar_carga_completa(page, timeout: int = 120):
    """
    Espera a que Outlook termine de cargar los contactos detectando el spinner.
    
    El spinner tiene dos estados:
    - Cargando: <div class="spinner spinnerAnimation">
    - Terminado: <div class="spinner"> (sin spinnerAnimation)
    
    Args:
        page: P√°gina de Playwright
        timeout: Tiempo m√°ximo de espera en segundos (default: 120)
    """
    spinner_selector = ".spinnerContainer .spinner"
    
    try:
        print("‚è≥ Esperando a que termine de cargar (detectando spinner)...")
        
        # Esperar a que el spinner aparezca Y tenga la clase spinnerAnimation (est√° cargando)
        # O esperar un poco si no aparece (m√°ximo 5 segundos)
        try:
            await page.wait_for_selector(f"{spinner_selector}.spinnerAnimation", state="attached", timeout=5000)
            print("   üîÑ Spinner detectado - cargando datos...")
        except:
            # Si no aparece el spinner en 5 segundos, probablemente ya carg√≥
            print("   ‚ö° No se detect√≥ spinner - los datos podr√≠an estar listos")
            await asyncio.sleep(1)
            return
        
        # Ahora esperar a que DESAPAREZCA la clase spinnerAnimation (termin√≥ de cargar)
        max_wait = timeout
        waited = 0
        check_interval = 0.5  # Revisar cada 0.5 segundos
        
        while waited < max_wait:
            # Verificar si el spinner todav√≠a est√° animando
            spinner_animating = await page.locator(f"{spinner_selector}.spinnerAnimation").count()
            
            if spinner_animating == 0:
                print("   ‚úÖ Carga completada (spinner desactivado)")
                # Espera adicional peque√±a para asegurar que el DOM se actualiz√≥
                await asyncio.sleep(1)
                return
            
            await asyncio.sleep(check_interval)
            waited += check_interval
            
            # Mostrar progreso cada 10 segundos
            if int(waited) % 10 == 0 and waited > 0:
                print(f"   ‚è≥ Todav√≠a cargando... ({int(waited)}s)")
        
        print(f"   ‚ö†Ô∏è Timeout despu√©s de {timeout}s - continuando de todos modos")
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è Error detectando spinner: {e} - usando espera de seguridad")
        await asyncio.sleep(3)

async def extraer_detalles_contacto(page, fila, nombre_contacto: str):
    """
    Hace clic en un contacto y extrae toda su informaci√≥n del panel de detalles.
    
    Args:
        page: P√°gina de Playwright
        fila: Elemento de la fila del contacto
        nombre_contacto: Nombre del contacto para logging
    
    Returns:
        dict con toda la informaci√≥n del contacto
    """
    detalles = {
        'nombre': nombre_contacto,
        'email': '',
        'telefono_trabajo': '',
        'sip': '',
        'departamento': '',
        'compania': '',
        'oficina': '',
        'direccion': ''
    }
    
    try:
        # 1. Hacer clic en el contacto para abrir el panel de detalles
        print(f"   üñ±Ô∏è  Haciendo clic en: {nombre_contacto}")
        await fila.click()
        
        # 2. Esperar a que cargue el panel - buscar el campo "Compa√±√≠a" como indicador
        try:
            # Esperamos hasta 20 segundos a que aparezca el campo Compa√±√≠a
            await page.wait_for_selector('span._rpc_F1:has-text("Compa√±√≠a:")', timeout=20000)
            print(f"   ‚úÖ Panel de detalles cargado")
        except:
            # Si no aparece Compa√±√≠a, esperamos un poco por si hay otros datos
            print(f"   ‚ö†Ô∏è Compa√±√≠a no encontrada - esperando 3s adicionales")
            await asyncio.sleep(3)
        
        # 3. Obtener todo el texto del popup para extracci√≥n basada en texto
        popup_selector = "div._rpc_M, div[class*='_rpc']"  # Selector del panel de detalles
        popup = page.locator(popup_selector).first
        
        try:
            popup_text = await popup.inner_text()
        except:
            # Fallback: obtener de toda la p√°gina
            popup_text = await page.inner_text("body")
        
        lines = popup_text.split('\n')
        
        # 4. EXTRAER CAMPOS usando estrategia basada en labels (m√°s robusta)
        
        # Email (personal, no el token)
        try:
            email_elements = await page.locator('span[title*="@"]').all()
            for elem in email_elements:
                try:
                    email_candidate = await elem.get_attribute('title')
                    if not email_candidate:
                        email_candidate = await elem.inner_text()
                    
                    email_candidate = email_candidate.strip()
                    
                    # Saltar tokens gen√©ricos (AGM564@, ASP123@, etc.)
                    import re
                    if re.match(r'^(ASP|AGM|AEM|ADM)\d+@', email_candidate, re.I):
                        continue
                    
                    # Este parece ser un email personal
                    if '@' in email_candidate and '.' in email_candidate:
                        detalles['email'] = email_candidate
                        break
                except:
                    continue
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extrayendo email: {e}")
        
        # Tel√©fono (buscar "Trabajo:" y extraer la siguiente l√≠nea)
        try:
            for i, line in enumerate(lines):
                if 'Trabajo:' in line and 'Departamento' not in line:
                    # El tel√©fono est√° en la siguiente l√≠nea
                    if i + 1 < len(lines):
                        phone_value = lines[i + 1].strip()
                        # Limpiar solo d√≠gitos y caracteres de tel√©fono
                        phone_clean = ''.join(c for c in phone_value if c.isdigit() or c in ['+', '-', ' ', '(', ')'])
                        if phone_clean.strip():
                            detalles['telefono_trabajo'] = phone_clean.strip()
                            break
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extrayendo tel√©fono: {e}")
        
        # SIP (buscar "MI:" y extraer la siguiente l√≠nea)
        try:
            for i, line in enumerate(lines):
                if line.strip() in ['MI:', 'MI', 'IM:', 'IM']:
                    # El SIP est√° en la siguiente l√≠nea
                    if i + 1 < len(lines):
                        sip_value = lines[i + 1].strip()
                        if sip_value.startswith('sip:'):
                            detalles['sip'] = sip_value
                            break
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extrayendo SIP: {e}")
        
        # Departamento
        try:
            for i, line in enumerate(lines):
                if 'Departamento:' in line:
                    # El valor puede estar en la misma l√≠nea o en la siguiente
                    value = line.replace('Departamento:', '').strip()
                    if not value and i + 1 < len(lines):
                        value = lines[i + 1].strip()
                    
                    if value and value.lower() not in ['directorio', 'directory', 'trabajo']:
                        detalles['departamento'] = value
                        break
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extrayendo departamento: {e}")
        
        # Compa√±√≠a
        try:
            for i, line in enumerate(lines):
                if 'Compa√±√≠a:' in line or 'Company:' in line:
                    # El valor puede estar en la misma l√≠nea o en la siguiente
                    value = line.replace('Compa√±√≠a:', '').replace('Company:', '').strip()
                    if not value and i + 1 < len(lines):
                        value = lines[i + 1].strip()
                    
                    if value and value.lower() not in ['directorio', 'directory']:
                        detalles['compania'] = value
                        break
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extrayendo compa√±√≠a: {e}")
        
        # Oficina
        try:
            for i, line in enumerate(lines):
                if 'Oficina:' in line or 'Office:' in line:
                    # El valor puede estar en la misma l√≠nea o en la siguiente
                    value = line.replace('Oficina:', '').replace('Office:', '').strip()
                    if not value and i + 1 < len(lines):
                        value = lines[i + 1].strip()
                    
                    if value and value.lower() not in ['directorio', 'directory']:
                        detalles['oficina'] = value
                        break
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extrayendo oficina: {e}")
        
        # Direcci√≥n (multil√≠nea - siguientes 2-3 l√≠neas despu√©s del label)
        try:
            for i, line in enumerate(lines):
                if 'Direcci√≥n profesional' in line or 'Business Address' in line:
                    # La direcci√≥n est√° en las siguientes 2-3 l√≠neas
                    address_parts = []
                    for j in range(1, 4):  # Revisar siguientes 3 l√≠neas
                        if i + j < len(lines):
                            line_text = lines[i + j].strip()
                            # Parar si encontramos otro label o l√≠nea vac√≠a
                            if line_text and not any(x in line_text for x in ['Departamento', 'Compa√±√≠a', 'Oficina', 'Trabajo:', 'MI:', 'Calendario']):
                                address_parts.append(line_text)
                            else:
                                break
                    
                    if address_parts:
                        detalles['direccion'] = ' '.join(address_parts)
                        break
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extrayendo direcci√≥n: {e}")
        
        print(f"   üìã Detalles: Email={detalles['email'][:30] if detalles['email'] else 'N/A'}, Dpto={detalles['departamento'][:30] if detalles['departamento'] else 'N/A'}, C√≠a={detalles['compania'][:30] if detalles['compania'] else 'N/A'}")
        
    except Exception as e:
        print(f"   ‚ùå Error extrayendo detalles: {e}")
    
    return detalles


async def scrape_outlook_contacts(page, max_contacts: int = 50):
    """Scrape de contactos de Outlook con scroll infinito y extracci√≥n de detalles
    
    Soporta reanudaci√≥n: Si existe un Excel previo, contin√∫a desde donde qued√≥.
    Usa metadata JSON para guardar el n√∫mero de scrolls y reanudar m√°s r√°pido.
    
    Args:
        page: P√°gina de Playwright
        max_contacts: N√∫mero m√°ximo TOTAL de contactos (incluyendo los ya guardados)
    """
    
    import pandas as pd
    from datetime import datetime
    import signal
    import sys
    import json
    
    # Selector de la fila
    row_selector = 'div[role="heading"]'
    
    # Buscar Excel m√°s reciente en data/
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)
    
    metadata_file = data_dir / "scraping_metadata.json"
    
    contactos_previos = []
    ultimo_nombre = None
    excel_path = None
    scroll_count_guardado = 0
    
    # Buscar el archivo Excel m√°s reciente
    excel_files = list(data_dir.glob("contactos_organos_judiciales_*.xlsx"))
    if excel_files:
        excel_path = max(excel_files, key=lambda p: p.stat().st_mtime)
        print(f"üìÇ Archivo Excel encontrado: {excel_path}")
        
        # Cargar metadata si existe
        if metadata_file.exists():
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                scroll_count_guardado = metadata.get('scroll_count', 0)
                print(f"üìú Metadata cargada - Scrolls previos: {scroll_count_guardado}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error leyendo metadata: {e}")
        
        try:
            df_previo = pd.read_excel(excel_path)
            contactos_previos = df_previo.to_dict('records')
            print(f"‚úÖ Cargados {len(contactos_previos)} contactos previos")
            
            if len(contactos_previos) > 0:
                ultimo_nombre = contactos_previos[-1]['nombre']
                print(f"üîÑ √öltimo contacto procesado: {ultimo_nombre}")
                print(f"üìä Faltan {max_contacts - len(contactos_previos)} contactos para llegar a {max_contacts}")
        except Exception as e:
            print(f"‚ö†Ô∏è Error leyendo Excel previo: {e}")
            contactos_previos = []
    else:
        print("üìù No se encontr√≥ Excel previo - comenzando desde cero")
    
    # Ajustar el l√≠mite seg√∫n lo que ya tenemos
    contactos_faltantes = max(0, max_contacts - len(contactos_previos))
    if contactos_faltantes == 0:
        print(f"‚úÖ Ya se alcanz√≥ el l√≠mite de {max_contacts} contactos")
        return contactos_previos
    
    print(f"üéØ Extrayendo {contactos_faltantes} contactos adicionales...")
    
    # 1. ESPERA CR√çTICA: Esperar a que aparezca al menos un contacto
    print(f"‚è≥ Esperando a que cargue la lista del Directorio...")
    try:
        await page.wait_for_selector(row_selector, state="visible", timeout=30000)
        print("‚úÖ Lista detectada")
    except Exception as e:
        print(f"‚ùå Error: La lista no carg√≥ a tiempo. \nDetalle: {e}")
        await page.screenshot(path="debug_error_lista.png")
        return contactos_previos

    # 2. Si hay scrolls guardados, ir directamente a esa posici√≥n
    scroll_count_actual = 0
    
    if scroll_count_guardado > 0:
        print(f"\n‚ö° Saltando directamente a scroll #{scroll_count_guardado}...")
        for i in range(scroll_count_guardado):
            await page.keyboard.press("PageDown")
            await asyncio.sleep(0.3)
            
            if i % 10 == 0 and i > 0:
                print(f"   Scrolleando... {i}/{scroll_count_guardado}")
        
        scroll_count_actual = scroll_count_guardado
        print(f"‚úÖ Posicionado en scroll #{scroll_count_actual}")
        await asyncio.sleep(2)  # Esperar a que cargue
    
    # 3. Variables para el scraping
    contactos_nuevos = []
    contactos_procesados = set(c['nombre'] for c in contactos_previos)
    last_item_count = 0
    retries = 0
    max_retries = 15
    
    # 4. Handler para guardar autom√°ticamente al interrumpir
    def guardar_y_salir(signum, frame):
        print("\n\n‚ö†Ô∏è Interrupci√≥n detectada - Guardando progreso...")
        todos_contactos = contactos_previos + contactos_nuevos
        if todos_contactos:
            guardar_excel(todos_contactos, data_dir, excel_path)
            # Guardar metadata con scroll count
            guardar_metadata(metadata_file, contactos_previos + contactos_nuevos, scroll_count_actual)
        print("üíæ Progreso guardado. Saliendo...")
        sys.exit(0)
    
    signal.signal(signal.SIGINT, guardar_y_salir)
    signal.signal(signal.SIGTERM, guardar_y_salir)

    print(f"\nüéØ Iniciando extracci√≥n de {contactos_faltantes} contactos nuevos...")

    # 5. Loop principal de extracci√≥n
    while True:
        filas = await page.locator(row_selector).all()

        if not filas:
            print("‚ö†Ô∏è No se encontraron filas visibles.")
            break

        for fila in filas:
            try:
                raw_name = await fila.get_attribute("aria-label")
                nombre = raw_name.strip() if raw_name else "Desconocido"

                # Filtro: may√∫sculas + coma
                if "," not in nombre or (not nombre.isupper()):
                    continue

                # Evitar duplicados
                if nombre in contactos_procesados:
                    continue
                
                contactos_procesados.add(nombre)
                
                total_actual = len(contactos_previos) + len(contactos_nuevos)
                print(f"\nüîç Procesando ({total_actual + 1}/{max_contacts}): {nombre}")
                
                # Extraer detalles
                detalles = await extraer_detalles_contacto(page, fila, nombre)
                
                # FILTRO: Solo ORGANOS JUDICIALES
                if detalles['compania'] and 'ORGANOS JUDICIALES' in detalles['compania'].upper():
                    contactos_nuevos.append(detalles)
                    print(f"‚úÖ Guardado ({total_actual + 1}/{max_contacts}) - ORGANOS JUDICIALES")
                else:
                    print(f"‚è≠Ô∏è  Omitido - Compa√±√≠a: {detalles['compania'] if detalles['compania'] else 'N/A'}")
                    contactos_procesados.remove(nombre)
                    continue
                
                # Verificar si alcanzamos el l√≠mite
                if len(contactos_previos) + len(contactos_nuevos) >= max_contacts:
                    print(f"\nüéØ ¬°L√≠mite alcanzado! Total: {max_contacts} contactos")
                    break

            except Exception as e:
                print(f"‚ùå Error procesando contacto: {e}")
        
        # Si alcanzamos el l√≠mite, salir
        if len(contactos_previos) + len(contactos_nuevos) >= max_contacts:
            break

        # Scroll
        try:
            if filas:
                await filas[-1].scroll_into_view_if_needed()
                await page.keyboard.press("PageDown")
                scroll_count_actual += 1  # Incrementar contador de scrolls
                await asyncio.sleep(0.5)
                await page.keyboard.press("PageDown")
                scroll_count_actual += 1  # Incrementar contador de scrolls
        except Exception as e:
            print(f"Error scroll: {e}")

        await esperar_carga_completa(page)

        # Verificaci√≥n de fin
        current_count = len(contactos_nuevos)
        if current_count == last_item_count:
            retries += 1
            print(f"Sin nuevos contactos... Intento {retries}/{max_retries}")
            
            await page.keyboard.press("End")
            await asyncio.sleep(0.5)
            await page.keyboard.press("PageDown")
            scroll_count_actual += 1
            await esperar_carga_completa(page)
            
            if retries >= max_retries:
                print(f"‚ö†Ô∏è Terminado despu√©s de {retries} intentos.")
                break
        else:
            retries = 0
        
        last_item_count = current_count
    
    # 6. Guardar resultado final
    todos_contactos = contactos_previos + contactos_nuevos
    if todos_contactos:
        guardar_excel(todos_contactos, data_dir, excel_path)
        guardar_metadata(metadata_file, todos_contactos, scroll_count_actual)
    
    return todos_contactos

def guardar_metadata(metadata_file, contactos, scroll_count):
    """Guarda metadata de la sesi√≥n de scraping"""
    import json
    from datetime import datetime
    
    metadata = {
        'ultimo_contacto': contactos[-1]['nombre'] if contactos else None,
        'total_contactos': len(contactos),
        'scroll_count': scroll_count,
        'timestamp': datetime.now().isoformat()
    }
    
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"üìù Metadata guardada - Scrolls: {scroll_count}")

def guardar_excel(contactos, data_dir, excel_path_existente=None):
    """Guarda contactos en Excel"""
    import pandas as pd
    from datetime import datetime
    
    if excel_path_existente and excel_path_existente.exists():
        # Actualizar el archivo existente
        excel_path = excel_path_existente
        print(f"\nüíæ Actualizando Excel existente: {excel_path}")
    else:
        # Crear nuevo archivo con timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        excel_filename = f"contactos_organos_judiciales_{timestamp}.xlsx"
        excel_path = data_dir / excel_filename
        print(f"\nüíæ Guardando {len(contactos)} contactos en nuevo Excel: {excel_path}")
    
    df = pd.DataFrame(contactos)
    
    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Contactos')
        
        worksheet = writer.sheets['Contactos']
        for idx, col in enumerate(df.columns):
            max_length = max(
                df[col].astype(str).apply(len).max(),
                len(col)
            ) + 2
            worksheet.column_dimensions[chr(65 + idx)].width = min(max_length, 50)
    
    print(f"‚úÖ Excel guardado: {excel_path}")
    print(f"üìä Total contactos de ORGANOS JUDICIALES: {len(contactos)}")


async def main():
    """Funci√≥n principal para debugging"""
    
    # Crear instancia del scraper
    # headless=False para ver el navegador mientras debugeas
    scraper = DebugScraper(headless=False)
    
    try:
        # 1. Iniciar sesi√≥n
        await scraper.iniciar_sesion("https://correoweb.madrid.org/owa/#path=/people")
        
        # Obtener la p√°gina despu√©s de inicializar
        page = scraper.page

        await page.wait_for_load_state("networkidle")

        directorio = page.get_by_label("Directorio", exact=True).locator("div").filter(has_text="Directorio").nth(1)
        await directorio.click()

        # Extraer contactos completos y guardar en Excel en data/
        await scrape_outlook_contacts(page, max_contacts=100)
        
        # await page.pause()

        await scraper.guardar_sesion()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interrumpido por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await scraper.cerrar()


if __name__ == "__main__":
    print("=" * 60)
    print("üêç DEBUG SCRAPER - Listo para debugging")
    print("=" * 60)
    asyncio.run(main())
